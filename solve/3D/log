KSP Object: 4 MPI processes
  type: cg
  maximum iterations=10000, initial guess is zero
  tolerances:  relative=1e-05, absolute=1e-50, divergence=10000.
  left preconditioning
  using PRECONDITIONED norm type for convergence test
PC Object: 4 MPI processes
  type: gamg
    type is MULTIPLICATIVE, levels=4 cycles=v
      Cycles per PCApply=1
      Using externally compute Galerkin coarse grid matrices
      GAMG specific options
        Threshold for dropping small values in graph on each level =   -0.05   -0.05   -0.05   -0.05  
        Threshold scaling factor for each level not specified = 1.
        AGG specific options
          Symmetric graph false
          Number of levels to square graph 10
          Number smoothing steps 1
        Complexity:    grid = 1.42799
  Coarse grid solver -- level -------------------------------
    KSP Object: (mg_coarse_) 4 MPI processes
      type: preonly
      maximum iterations=10000, initial guess is zero
      tolerances:  relative=1e-05, absolute=1e-50, divergence=10000.
      left preconditioning
      using NONE norm type for convergence test
    PC Object: (mg_coarse_) 4 MPI processes
      type: bjacobi
        number of blocks = 4
        Local solver information for first block is in the following KSP and PC objects on rank 0:
        Use -mg_coarse_ksp_view ::ascii_info_detail to display information for all blocks
      KSP Object: (mg_coarse_sub_) 1 MPI processes
        type: preonly
        maximum iterations=1, initial guess is zero
        tolerances:  relative=1e-05, absolute=1e-50, divergence=10000.
        left preconditioning
        using NONE norm type for convergence test
      PC Object: (mg_coarse_sub_) 1 MPI processes
        type: lu
          out-of-place factorization
          tolerance for zero pivot 2.22045e-14
          using diagonal shift on blocks to prevent zero pivot [INBLOCKS]
          matrix ordering: nd
          factor fill ratio given 5., needed 1.1828
            Factored matrix follows:
              Mat Object: 1 MPI processes
                type: seqaijkokkos
                rows=16, cols=16
                package used to perform factorization: kokkos
                total: nonzeros=220, allocated nonzeros=220
                  using I-node routines: found 5 nodes, limit used is 5
        linear system matrix = precond matrix:
        Mat Object: (mg_coarse_sub_) 1 MPI processes
          type: seqaijkokkos
          rows=16, cols=16
          total: nonzeros=186, allocated nonzeros=186
          total number of mallocs used during MatSetValues calls=0
            using I-node routines: found 11 nodes, limit used is 5
      linear system matrix = precond matrix:
      Mat Object: 4 MPI processes
        type: mpiaijkokkos
        rows=16, cols=16
        total: nonzeros=186, allocated nonzeros=186
        total number of mallocs used during MatSetValues calls=0
          using I-node (on process 0) routines: found 11 nodes, limit used is 5
  Down solver (pre-smoother) on level 1 -------------------------------
    KSP Object: (mg_levels_1_) 4 MPI processes
      type: chebyshev
        eigenvalue estimates used:  min = 0.133228, max = 1.4655
        eigenvalues estimate via gmres min 0.285788, max 1.33228
        eigenvalues estimated using gmres with translations  [0. 0.1; 0. 1.1]
        KSP Object: (mg_levels_1_esteig_) 4 MPI processes
          type: gmres
            restart=30, using Classical (unmodified) Gram-Schmidt Orthogonalization with no iterative refinement
            happy breakdown tolerance 1e-30
          maximum iterations=10, initial guess is zero
          tolerances:  relative=1e-12, absolute=1e-50, divergence=10000.
          left preconditioning
          using PRECONDITIONED norm type for convergence test
        estimating eigenvalues using noisy right hand side
      maximum iterations=2, nonzero initial guess
      tolerances:  relative=1e-05, absolute=1e-50, divergence=10000.
      left preconditioning
      using NONE norm type for convergence test
    PC Object: (mg_levels_1_) 4 MPI processes
      type: sor
        type = local_symmetric, iterations = 1, local iterations = 1, omega = 1.
      linear system matrix = precond matrix:
      Mat Object: 4 MPI processes
        type: mpiaijkokkos
        rows=1477, cols=1477
        total: nonzeros=75809, allocated nonzeros=75809
        total number of mallocs used during MatSetValues calls=0
          not using I-node (on process 0) routines
  Up solver (post-smoother) same as down solver (pre-smoother)
  Down solver (pre-smoother) on level 2 -------------------------------
    KSP Object: (mg_levels_2_) 4 MPI processes
      type: chebyshev
        eigenvalue estimates used:  min = 0.135914, max = 1.49505
        eigenvalues estimate via gmres min 0.0401755, max 1.35914
        eigenvalues estimated using gmres with translations  [0. 0.1; 0. 1.1]
        KSP Object: (mg_levels_2_esteig_) 4 MPI processes
          type: gmres
            restart=30, using Classical (unmodified) Gram-Schmidt Orthogonalization with no iterative refinement
            happy breakdown tolerance 1e-30
          maximum iterations=10, initial guess is zero
          tolerances:  relative=1e-12, absolute=1e-50, divergence=10000.
          left preconditioning
          using PRECONDITIONED norm type for convergence test
        estimating eigenvalues using noisy right hand side
      maximum iterations=2, nonzero initial guess
      tolerances:  relative=1e-05, absolute=1e-50, divergence=10000.
      left preconditioning
      using NONE norm type for convergence test
    PC Object: (mg_levels_2_) 4 MPI processes
      type: sor
        type = local_symmetric, iterations = 1, local iterations = 1, omega = 1.
      linear system matrix = precond matrix:
      Mat Object: 4 MPI processes
        type: mpiaijkokkos
        rows=95207, cols=95207
        total: nonzeros=3033895, allocated nonzeros=3033895
        total number of mallocs used during MatSetValues calls=0
          not using I-node (on process 0) routines
  Up solver (post-smoother) same as down solver (pre-smoother)
  Down solver (pre-smoother) on level 3 -------------------------------
    KSP Object: (mg_levels_3_) 4 MPI processes
      type: chebyshev
        eigenvalue estimates used:  min = 0.139009, max = 1.5291
        eigenvalues estimate via gmres min 0.0287622, max 1.39009
        eigenvalues estimated using gmres with translations  [0. 0.1; 0. 1.1]
        KSP Object: (mg_levels_3_esteig_) 4 MPI processes
          type: gmres
            restart=30, using Classical (unmodified) Gram-Schmidt Orthogonalization with no iterative refinement
            happy breakdown tolerance 1e-30
          maximum iterations=10, initial guess is zero
          tolerances:  relative=1e-12, absolute=1e-50, divergence=10000.
          left preconditioning
          using PRECONDITIONED norm type for convergence test
        estimating eigenvalues using noisy right hand side
      maximum iterations=2, nonzero initial guess
      tolerances:  relative=1e-05, absolute=1e-50, divergence=10000.
      left preconditioning
      using NONE norm type for convergence test
    PC Object: (mg_levels_3_) 4 MPI processes
      type: sor
        type = local_symmetric, iterations = 1, local iterations = 1, omega = 1.
      linear system matrix = precond matrix:
      Mat Object: 4 MPI processes
        type: mpiaijkokkos
        rows=1048576, cols=1048576
        total: nonzeros=7266304, allocated nonzeros=7266304
        total number of mallocs used during MatSetValues calls=0
  Up solver (post-smoother) same as down solver (pre-smoother)
  linear system matrix = precond matrix:
  Mat Object: 4 MPI processes
    type: mpiaijkokkos
    rows=1048576, cols=1048576
    total: nonzeros=7266304, allocated nonzeros=7266304
    total number of mallocs used during MatSetValues calls=0
KSP Object: 4 MPI processes
  type: cg
  maximum iterations=10000, initial guess is zero
  tolerances:  relative=1e-05, absolute=1e-50, divergence=10000.
  left preconditioning
  using PRECONDITIONED norm type for convergence test
PC Object: 4 MPI processes
  type: gamg
    type is MULTIPLICATIVE, levels=4 cycles=v
      Cycles per PCApply=1
      Using externally compute Galerkin coarse grid matrices
      GAMG specific options
        Threshold for dropping small values in graph on each level =   -0.05   -0.05   -0.05   -0.05  
        Threshold scaling factor for each level not specified = 1.
        AGG specific options
          Symmetric graph false
          Number of levels to square graph 10
          Number smoothing steps 1
        Complexity:    grid = 1.42799
  Coarse grid solver -- level -------------------------------
    KSP Object: (mg_coarse_) 4 MPI processes
      type: preonly
      maximum iterations=10000, initial guess is zero
      tolerances:  relative=1e-05, absolute=1e-50, divergence=10000.
      left preconditioning
      using NONE norm type for convergence test
    PC Object: (mg_coarse_) 4 MPI processes
      type: bjacobi
        number of blocks = 4
        Local solver information for first block is in the following KSP and PC objects on rank 0:
        Use -mg_coarse_ksp_view ::ascii_info_detail to display information for all blocks
      KSP Object: (mg_coarse_sub_) 1 MPI processes
        type: preonly
        maximum iterations=1, initial guess is zero
        tolerances:  relative=1e-05, absolute=1e-50, divergence=10000.
        left preconditioning
        using NONE norm type for convergence test
      PC Object: (mg_coarse_sub_) 1 MPI processes
        type: lu
          out-of-place factorization
          tolerance for zero pivot 2.22045e-14
          using diagonal shift on blocks to prevent zero pivot [INBLOCKS]
          matrix ordering: nd
          factor fill ratio given 5., needed 1.1828
            Factored matrix follows:
              Mat Object: 1 MPI processes
                type: seqaijkokkos
                rows=16, cols=16
                package used to perform factorization: kokkos
                total: nonzeros=220, allocated nonzeros=220
                  using I-node routines: found 5 nodes, limit used is 5
        linear system matrix = precond matrix:
        Mat Object: (mg_coarse_sub_) 1 MPI processes
          type: seqaijkokkos
          rows=16, cols=16
          total: nonzeros=186, allocated nonzeros=186
          total number of mallocs used during MatSetValues calls=0
            using I-node routines: found 11 nodes, limit used is 5
      linear system matrix = precond matrix:
      Mat Object: 4 MPI processes
        type: mpiaijkokkos
        rows=16, cols=16
        total: nonzeros=186, allocated nonzeros=186
        total number of mallocs used during MatSetValues calls=0
          using I-node (on process 0) routines: found 11 nodes, limit used is 5
  Down solver (pre-smoother) on level 1 -------------------------------
    KSP Object: (mg_levels_1_) 4 MPI processes
      type: chebyshev
        eigenvalue estimates used:  min = 0.133228, max = 1.4655
        eigenvalues estimate via gmres min 0.285788, max 1.33228
        eigenvalues estimated using gmres with translations  [0. 0.1; 0. 1.1]
        KSP Object: (mg_levels_1_esteig_) 4 MPI processes
          type: gmres
            restart=30, using Classical (unmodified) Gram-Schmidt Orthogonalization with no iterative refinement
            happy breakdown tolerance 1e-30
          maximum iterations=10, initial guess is zero
          tolerances:  relative=1e-12, absolute=1e-50, divergence=10000.
          left preconditioning
          using PRECONDITIONED norm type for convergence test
        estimating eigenvalues using noisy right hand side
      maximum iterations=2, nonzero initial guess
      tolerances:  relative=1e-05, absolute=1e-50, divergence=10000.
      left preconditioning
      using NONE norm type for convergence test
    PC Object: (mg_levels_1_) 4 MPI processes
      type: sor
        type = local_symmetric, iterations = 1, local iterations = 1, omega = 1.
      linear system matrix = precond matrix:
      Mat Object: 4 MPI processes
        type: mpiaijkokkos
        rows=1477, cols=1477
        total: nonzeros=75809, allocated nonzeros=75809
        total number of mallocs used during MatSetValues calls=0
          not using I-node (on process 0) routines
  Up solver (post-smoother) same as down solver (pre-smoother)
  Down solver (pre-smoother) on level 2 -------------------------------
    KSP Object: (mg_levels_2_) 4 MPI processes
      type: chebyshev
        eigenvalue estimates used:  min = 0.135914, max = 1.49505
        eigenvalues estimate via gmres min 0.0401755, max 1.35914
        eigenvalues estimated using gmres with translations  [0. 0.1; 0. 1.1]
        KSP Object: (mg_levels_2_esteig_) 4 MPI processes
          type: gmres
            restart=30, using Classical (unmodified) Gram-Schmidt Orthogonalization with no iterative refinement
            happy breakdown tolerance 1e-30
          maximum iterations=10, initial guess is zero
          tolerances:  relative=1e-12, absolute=1e-50, divergence=10000.
          left preconditioning
          using PRECONDITIONED norm type for convergence test
        estimating eigenvalues using noisy right hand side
      maximum iterations=2, nonzero initial guess
      tolerances:  relative=1e-05, absolute=1e-50, divergence=10000.
      left preconditioning
      using NONE norm type for convergence test
    PC Object: (mg_levels_2_) 4 MPI processes
      type: sor
        type = local_symmetric, iterations = 1, local iterations = 1, omega = 1.
      linear system matrix = precond matrix:
      Mat Object: 4 MPI processes
        type: mpiaijkokkos
        rows=95207, cols=95207
        total: nonzeros=3033895, allocated nonzeros=3033895
        total number of mallocs used during MatSetValues calls=0
          not using I-node (on process 0) routines
  Up solver (post-smoother) same as down solver (pre-smoother)
  Down solver (pre-smoother) on level 3 -------------------------------
    KSP Object: (mg_levels_3_) 4 MPI processes
      type: chebyshev
        eigenvalue estimates used:  min = 0.139009, max = 1.5291
        eigenvalues estimate via gmres min 0.0287622, max 1.39009
        eigenvalues estimated using gmres with translations  [0. 0.1; 0. 1.1]
        KSP Object: (mg_levels_3_esteig_) 4 MPI processes
          type: gmres
            restart=30, using Classical (unmodified) Gram-Schmidt Orthogonalization with no iterative refinement
            happy breakdown tolerance 1e-30
          maximum iterations=10, initial guess is zero
          tolerances:  relative=1e-12, absolute=1e-50, divergence=10000.
          left preconditioning
          using PRECONDITIONED norm type for convergence test
        estimating eigenvalues using noisy right hand side
      maximum iterations=2, nonzero initial guess
      tolerances:  relative=1e-05, absolute=1e-50, divergence=10000.
      left preconditioning
      using NONE norm type for convergence test
    PC Object: (mg_levels_3_) 4 MPI processes
      type: sor
        type = local_symmetric, iterations = 1, local iterations = 1, omega = 1.
      linear system matrix = precond matrix:
      Mat Object: 4 MPI processes
        type: mpiaijkokkos
        rows=1048576, cols=1048576
        total: nonzeros=7266304, allocated nonzeros=7266304
        total number of mallocs used during MatSetValues calls=0
  Up solver (post-smoother) same as down solver (pre-smoother)
  linear system matrix = precond matrix:
  Mat Object: 4 MPI processes
    type: mpiaijkokkos
    rows=1048576, cols=1048576
    total: nonzeros=7266304, allocated nonzeros=7266304
    total number of mallocs used during MatSetValues calls=0
KSP Object: 4 MPI processes
  type: cg
  maximum iterations=10000, initial guess is zero
  tolerances:  relative=1e-05, absolute=1e-50, divergence=10000.
  left preconditioning
  using PRECONDITIONED norm type for convergence test
PC Object: 4 MPI processes
  type: gamg
    type is MULTIPLICATIVE, levels=4 cycles=v
      Cycles per PCApply=1
      Using externally compute Galerkin coarse grid matrices
      GAMG specific options
        Threshold for dropping small values in graph on each level =   -0.05   -0.05   -0.05   -0.05  
        Threshold scaling factor for each level not specified = 1.
        AGG specific options
          Symmetric graph false
          Number of levels to square graph 10
          Number smoothing steps 1
        Complexity:    grid = 1.42799
  Coarse grid solver -- level -------------------------------
    KSP Object: (mg_coarse_) 4 MPI processes
      type: preonly
      maximum iterations=10000, initial guess is zero
      tolerances:  relative=1e-05, absolute=1e-50, divergence=10000.
      left preconditioning
      using NONE norm type for convergence test
    PC Object: (mg_coarse_) 4 MPI processes
      type: bjacobi
        number of blocks = 4
        Local solver information for first block is in the following KSP and PC objects on rank 0:
        Use -mg_coarse_ksp_view ::ascii_info_detail to display information for all blocks
      KSP Object: (mg_coarse_sub_) 1 MPI processes
        type: preonly
        maximum iterations=1, initial guess is zero
        tolerances:  relative=1e-05, absolute=1e-50, divergence=10000.
        left preconditioning
        using NONE norm type for convergence test
      PC Object: (mg_coarse_sub_) 1 MPI processes
        type: lu
          out-of-place factorization
          tolerance for zero pivot 2.22045e-14
          using diagonal shift on blocks to prevent zero pivot [INBLOCKS]
          matrix ordering: nd
          factor fill ratio given 5., needed 1.1828
            Factored matrix follows:
              Mat Object: 1 MPI processes
                type: seqaijkokkos
                rows=16, cols=16
                package used to perform factorization: kokkos
                total: nonzeros=220, allocated nonzeros=220
                  using I-node routines: found 5 nodes, limit used is 5
        linear system matrix = precond matrix:
        Mat Object: (mg_coarse_sub_) 1 MPI processes
          type: seqaijkokkos
          rows=16, cols=16
          total: nonzeros=186, allocated nonzeros=186
          total number of mallocs used during MatSetValues calls=0
            using I-node routines: found 11 nodes, limit used is 5
      linear system matrix = precond matrix:
      Mat Object: 4 MPI processes
        type: mpiaijkokkos
        rows=16, cols=16
        total: nonzeros=186, allocated nonzeros=186
        total number of mallocs used during MatSetValues calls=0
          using I-node (on process 0) routines: found 11 nodes, limit used is 5
  Down solver (pre-smoother) on level 1 -------------------------------
    KSP Object: (mg_levels_1_) 4 MPI processes
      type: chebyshev
        eigenvalue estimates used:  min = 0.133228, max = 1.4655
        eigenvalues estimate via gmres min 0.285788, max 1.33228
        eigenvalues estimated using gmres with translations  [0. 0.1; 0. 1.1]
        KSP Object: (mg_levels_1_esteig_) 4 MPI processes
          type: gmres
            restart=30, using Classical (unmodified) Gram-Schmidt Orthogonalization with no iterative refinement
            happy breakdown tolerance 1e-30
          maximum iterations=10, initial guess is zero
          tolerances:  relative=1e-12, absolute=1e-50, divergence=10000.
          left preconditioning
          using PRECONDITIONED norm type for convergence test
        estimating eigenvalues using noisy right hand side
      maximum iterations=2, nonzero initial guess
      tolerances:  relative=1e-05, absolute=1e-50, divergence=10000.
      left preconditioning
      using NONE norm type for convergence test
    PC Object: (mg_levels_1_) 4 MPI processes
      type: sor
        type = local_symmetric, iterations = 1, local iterations = 1, omega = 1.
      linear system matrix = precond matrix:
      Mat Object: 4 MPI processes
        type: mpiaijkokkos
        rows=1477, cols=1477
        total: nonzeros=75809, allocated nonzeros=75809
        total number of mallocs used during MatSetValues calls=0
          not using I-node (on process 0) routines
  Up solver (post-smoother) same as down solver (pre-smoother)
  Down solver (pre-smoother) on level 2 -------------------------------
    KSP Object: (mg_levels_2_) 4 MPI processes
      type: chebyshev
        eigenvalue estimates used:  min = 0.135914, max = 1.49505
        eigenvalues estimate via gmres min 0.0401755, max 1.35914
        eigenvalues estimated using gmres with translations  [0. 0.1; 0. 1.1]
        KSP Object: (mg_levels_2_esteig_) 4 MPI processes
          type: gmres
            restart=30, using Classical (unmodified) Gram-Schmidt Orthogonalization with no iterative refinement
            happy breakdown tolerance 1e-30
          maximum iterations=10, initial guess is zero
          tolerances:  relative=1e-12, absolute=1e-50, divergence=10000.
          left preconditioning
          using PRECONDITIONED norm type for convergence test
        estimating eigenvalues using noisy right hand side
      maximum iterations=2, nonzero initial guess
      tolerances:  relative=1e-05, absolute=1e-50, divergence=10000.
      left preconditioning
      using NONE norm type for convergence test
    PC Object: (mg_levels_2_) 4 MPI processes
      type: sor
        type = local_symmetric, iterations = 1, local iterations = 1, omega = 1.
      linear system matrix = precond matrix:
      Mat Object: 4 MPI processes
        type: mpiaijkokkos
        rows=95207, cols=95207
        total: nonzeros=3033895, allocated nonzeros=3033895
        total number of mallocs used during MatSetValues calls=0
          not using I-node (on process 0) routines
  Up solver (post-smoother) same as down solver (pre-smoother)
  Down solver (pre-smoother) on level 3 -------------------------------
    KSP Object: (mg_levels_3_) 4 MPI processes
      type: chebyshev
        eigenvalue estimates used:  min = 0.139009, max = 1.5291
        eigenvalues estimate via gmres min 0.0287622, max 1.39009
        eigenvalues estimated using gmres with translations  [0. 0.1; 0. 1.1]
        KSP Object: (mg_levels_3_esteig_) 4 MPI processes
          type: gmres
            restart=30, using Classical (unmodified) Gram-Schmidt Orthogonalization with no iterative refinement
            happy breakdown tolerance 1e-30
          maximum iterations=10, initial guess is zero
          tolerances:  relative=1e-12, absolute=1e-50, divergence=10000.
          left preconditioning
          using PRECONDITIONED norm type for convergence test
        estimating eigenvalues using noisy right hand side
      maximum iterations=2, nonzero initial guess
      tolerances:  relative=1e-05, absolute=1e-50, divergence=10000.
      left preconditioning
      using NONE norm type for convergence test
    PC Object: (mg_levels_3_) 4 MPI processes
      type: sor
        type = local_symmetric, iterations = 1, local iterations = 1, omega = 1.
      linear system matrix = precond matrix:
      Mat Object: 4 MPI processes
        type: mpiaijkokkos
        rows=1048576, cols=1048576
        total: nonzeros=7266304, allocated nonzeros=7266304
        total number of mallocs used during MatSetValues calls=0
  Up solver (post-smoother) same as down solver (pre-smoother)
  linear system matrix = precond matrix:
  Mat Object: 4 MPI processes
    type: mpiaijkokkos
    rows=1048576, cols=1048576
    total: nonzeros=7266304, allocated nonzeros=7266304
    total number of mallocs used during MatSetValues calls=0
KSP Object: 4 MPI processes
  type: cg
  maximum iterations=10000, initial guess is zero
  tolerances:  relative=1e-05, absolute=1e-50, divergence=10000.
  left preconditioning
  using PRECONDITIONED norm type for convergence test
PC Object: 4 MPI processes
  type: gamg
    type is MULTIPLICATIVE, levels=4 cycles=v
      Cycles per PCApply=1
      Using externally compute Galerkin coarse grid matrices
      GAMG specific options
        Threshold for dropping small values in graph on each level =   -0.05   -0.05   -0.05   -0.05  
        Threshold scaling factor for each level not specified = 1.
        AGG specific options
          Symmetric graph false
          Number of levels to square graph 10
          Number smoothing steps 1
        Complexity:    grid = 1.42799
  Coarse grid solver -- level -------------------------------
    KSP Object: (mg_coarse_) 4 MPI processes
      type: preonly
      maximum iterations=10000, initial guess is zero
      tolerances:  relative=1e-05, absolute=1e-50, divergence=10000.
      left preconditioning
      using NONE norm type for convergence test
    PC Object: (mg_coarse_) 4 MPI processes
      type: bjacobi
        number of blocks = 4
        Local solver information for first block is in the following KSP and PC objects on rank 0:
        Use -mg_coarse_ksp_view ::ascii_info_detail to display information for all blocks
      KSP Object: (mg_coarse_sub_) 1 MPI processes
        type: preonly
        maximum iterations=1, initial guess is zero
        tolerances:  relative=1e-05, absolute=1e-50, divergence=10000.
        left preconditioning
        using NONE norm type for convergence test
      PC Object: (mg_coarse_sub_) 1 MPI processes
        type: lu
          out-of-place factorization
          tolerance for zero pivot 2.22045e-14
          using diagonal shift on blocks to prevent zero pivot [INBLOCKS]
          matrix ordering: nd
          factor fill ratio given 5., needed 1.1828
            Factored matrix follows:
              Mat Object: 1 MPI processes
                type: seqaijkokkos
                rows=16, cols=16
                package used to perform factorization: kokkos
                total: nonzeros=220, allocated nonzeros=220
                  using I-node routines: found 5 nodes, limit used is 5
        linear system matrix = precond matrix:
        Mat Object: (mg_coarse_sub_) 1 MPI processes
          type: seqaijkokkos
          rows=16, cols=16
          total: nonzeros=186, allocated nonzeros=186
          total number of mallocs used during MatSetValues calls=0
            using I-node routines: found 11 nodes, limit used is 5
      linear system matrix = precond matrix:
      Mat Object: 4 MPI processes
        type: mpiaijkokkos
        rows=16, cols=16
        total: nonzeros=186, allocated nonzeros=186
        total number of mallocs used during MatSetValues calls=0
          using I-node (on process 0) routines: found 11 nodes, limit used is 5
  Down solver (pre-smoother) on level 1 -------------------------------
    KSP Object: (mg_levels_1_) 4 MPI processes
      type: chebyshev
        eigenvalue estimates used:  min = 0.133228, max = 1.4655
        eigenvalues estimate via gmres min 0.285788, max 1.33228
        eigenvalues estimated using gmres with translations  [0. 0.1; 0. 1.1]
        KSP Object: (mg_levels_1_esteig_) 4 MPI processes
          type: gmres
            restart=30, using Classical (unmodified) Gram-Schmidt Orthogonalization with no iterative refinement
            happy breakdown tolerance 1e-30
          maximum iterations=10, initial guess is zero
          tolerances:  relative=1e-12, absolute=1e-50, divergence=10000.
          left preconditioning
          using PRECONDITIONED norm type for convergence test
        estimating eigenvalues using noisy right hand side
      maximum iterations=2, nonzero initial guess
      tolerances:  relative=1e-05, absolute=1e-50, divergence=10000.
      left preconditioning
      using NONE norm type for convergence test
    PC Object: (mg_levels_1_) 4 MPI processes
      type: sor
        type = local_symmetric, iterations = 1, local iterations = 1, omega = 1.
      linear system matrix = precond matrix:
      Mat Object: 4 MPI processes
        type: mpiaijkokkos
        rows=1477, cols=1477
        total: nonzeros=75809, allocated nonzeros=75809
        total number of mallocs used during MatSetValues calls=0
          not using I-node (on process 0) routines
  Up solver (post-smoother) same as down solver (pre-smoother)
  Down solver (pre-smoother) on level 2 -------------------------------
    KSP Object: (mg_levels_2_) 4 MPI processes
      type: chebyshev
        eigenvalue estimates used:  min = 0.135914, max = 1.49505
        eigenvalues estimate via gmres min 0.0401755, max 1.35914
        eigenvalues estimated using gmres with translations  [0. 0.1; 0. 1.1]
        KSP Object: (mg_levels_2_esteig_) 4 MPI processes
          type: gmres
            restart=30, using Classical (unmodified) Gram-Schmidt Orthogonalization with no iterative refinement
            happy breakdown tolerance 1e-30
          maximum iterations=10, initial guess is zero
          tolerances:  relative=1e-12, absolute=1e-50, divergence=10000.
          left preconditioning
          using PRECONDITIONED norm type for convergence test
        estimating eigenvalues using noisy right hand side
      maximum iterations=2, nonzero initial guess
      tolerances:  relative=1e-05, absolute=1e-50, divergence=10000.
      left preconditioning
      using NONE norm type for convergence test
    PC Object: (mg_levels_2_) 4 MPI processes
      type: sor
        type = local_symmetric, iterations = 1, local iterations = 1, omega = 1.
      linear system matrix = precond matrix:
      Mat Object: 4 MPI processes
        type: mpiaijkokkos
        rows=95207, cols=95207
        total: nonzeros=3033895, allocated nonzeros=3033895
        total number of mallocs used during MatSetValues calls=0
          not using I-node (on process 0) routines
  Up solver (post-smoother) same as down solver (pre-smoother)
  Down solver (pre-smoother) on level 3 -------------------------------
    KSP Object: (mg_levels_3_) 4 MPI processes
      type: chebyshev
        eigenvalue estimates used:  min = 0.139009, max = 1.5291
        eigenvalues estimate via gmres min 0.0287622, max 1.39009
        eigenvalues estimated using gmres with translations  [0. 0.1; 0. 1.1]
        KSP Object: (mg_levels_3_esteig_) 4 MPI processes
          type: gmres
            restart=30, using Classical (unmodified) Gram-Schmidt Orthogonalization with no iterative refinement
            happy breakdown tolerance 1e-30
          maximum iterations=10, initial guess is zero
          tolerances:  relative=1e-12, absolute=1e-50, divergence=10000.
          left preconditioning
          using PRECONDITIONED norm type for convergence test
        estimating eigenvalues using noisy right hand side
      maximum iterations=2, nonzero initial guess
      tolerances:  relative=1e-05, absolute=1e-50, divergence=10000.
      left preconditioning
      using NONE norm type for convergence test
    PC Object: (mg_levels_3_) 4 MPI processes
      type: sor
        type = local_symmetric, iterations = 1, local iterations = 1, omega = 1.
      linear system matrix = precond matrix:
      Mat Object: 4 MPI processes
        type: mpiaijkokkos
        rows=1048576, cols=1048576
        total: nonzeros=7266304, allocated nonzeros=7266304
        total number of mallocs used during MatSetValues calls=0
  Up solver (post-smoother) same as down solver (pre-smoother)
  linear system matrix = precond matrix:
  Mat Object: 4 MPI processes
    type: mpiaijkokkos
    rows=1048576, cols=1048576
    total: nonzeros=7266304, allocated nonzeros=7266304
    total number of mallocs used during MatSetValues calls=0
KSP Object: 4 MPI processes
  type: cg
  maximum iterations=10000, initial guess is zero
  tolerances:  relative=1e-05, absolute=1e-50, divergence=10000.
  left preconditioning
  using PRECONDITIONED norm type for convergence test
PC Object: 4 MPI processes
  type: gamg
    type is MULTIPLICATIVE, levels=4 cycles=v
      Cycles per PCApply=1
      Using externally compute Galerkin coarse grid matrices
      GAMG specific options
        Threshold for dropping small values in graph on each level =   -0.05   -0.05   -0.05   -0.05  
        Threshold scaling factor for each level not specified = 1.
        AGG specific options
          Symmetric graph false
          Number of levels to square graph 10
          Number smoothing steps 1
        Complexity:    grid = 1.42799
  Coarse grid solver -- level -------------------------------
    KSP Object: (mg_coarse_) 4 MPI processes
      type: preonly
      maximum iterations=10000, initial guess is zero
      tolerances:  relative=1e-05, absolute=1e-50, divergence=10000.
      left preconditioning
      using NONE norm type for convergence test
    PC Object: (mg_coarse_) 4 MPI processes
      type: bjacobi
        number of blocks = 4
        Local solver information for first block is in the following KSP and PC objects on rank 0:
        Use -mg_coarse_ksp_view ::ascii_info_detail to display information for all blocks
      KSP Object: (mg_coarse_sub_) 1 MPI processes
        type: preonly
        maximum iterations=1, initial guess is zero
        tolerances:  relative=1e-05, absolute=1e-50, divergence=10000.
        left preconditioning
        using NONE norm type for convergence test
      PC Object: (mg_coarse_sub_) 1 MPI processes
        type: lu
          out-of-place factorization
          tolerance for zero pivot 2.22045e-14
          using diagonal shift on blocks to prevent zero pivot [INBLOCKS]
          matrix ordering: nd
          factor fill ratio given 5., needed 1.1828
            Factored matrix follows:
              Mat Object: 1 MPI processes
                type: seqaijkokkos
                rows=16, cols=16
                package used to perform factorization: kokkos
                total: nonzeros=220, allocated nonzeros=220
                  using I-node routines: found 5 nodes, limit used is 5
        linear system matrix = precond matrix:
        Mat Object: (mg_coarse_sub_) 1 MPI processes
          type: seqaijkokkos
          rows=16, cols=16
          total: nonzeros=186, allocated nonzeros=186
          total number of mallocs used during MatSetValues calls=0
            using I-node routines: found 11 nodes, limit used is 5
      linear system matrix = precond matrix:
      Mat Object: 4 MPI processes
        type: mpiaijkokkos
        rows=16, cols=16
        total: nonzeros=186, allocated nonzeros=186
        total number of mallocs used during MatSetValues calls=0
          using I-node (on process 0) routines: found 11 nodes, limit used is 5
  Down solver (pre-smoother) on level 1 -------------------------------
    KSP Object: (mg_levels_1_) 4 MPI processes
      type: chebyshev
        eigenvalue estimates used:  min = 0.133228, max = 1.4655
        eigenvalues estimate via gmres min 0.285788, max 1.33228
        eigenvalues estimated using gmres with translations  [0. 0.1; 0. 1.1]
        KSP Object: (mg_levels_1_esteig_) 4 MPI processes
          type: gmres
            restart=30, using Classical (unmodified) Gram-Schmidt Orthogonalization with no iterative refinement
            happy breakdown tolerance 1e-30
          maximum iterations=10, initial guess is zero
          tolerances:  relative=1e-12, absolute=1e-50, divergence=10000.
          left preconditioning
          using PRECONDITIONED norm type for convergence test
        estimating eigenvalues using noisy right hand side
      maximum iterations=2, nonzero initial guess
      tolerances:  relative=1e-05, absolute=1e-50, divergence=10000.
      left preconditioning
      using NONE norm type for convergence test
    PC Object: (mg_levels_1_) 4 MPI processes
      type: sor
        type = local_symmetric, iterations = 1, local iterations = 1, omega = 1.
      linear system matrix = precond matrix:
      Mat Object: 4 MPI processes
        type: mpiaijkokkos
        rows=1477, cols=1477
        total: nonzeros=75809, allocated nonzeros=75809
        total number of mallocs used during MatSetValues calls=0
          not using I-node (on process 0) routines
  Up solver (post-smoother) same as down solver (pre-smoother)
  Down solver (pre-smoother) on level 2 -------------------------------
    KSP Object: (mg_levels_2_) 4 MPI processes
      type: chebyshev
        eigenvalue estimates used:  min = 0.135914, max = 1.49505
        eigenvalues estimate via gmres min 0.0401755, max 1.35914
        eigenvalues estimated using gmres with translations  [0. 0.1; 0. 1.1]
        KSP Object: (mg_levels_2_esteig_) 4 MPI processes
          type: gmres
            restart=30, using Classical (unmodified) Gram-Schmidt Orthogonalization with no iterative refinement
            happy breakdown tolerance 1e-30
          maximum iterations=10, initial guess is zero
          tolerances:  relative=1e-12, absolute=1e-50, divergence=10000.
          left preconditioning
          using PRECONDITIONED norm type for convergence test
        estimating eigenvalues using noisy right hand side
      maximum iterations=2, nonzero initial guess
      tolerances:  relative=1e-05, absolute=1e-50, divergence=10000.
      left preconditioning
      using NONE norm type for convergence test
    PC Object: (mg_levels_2_) 4 MPI processes
      type: sor
        type = local_symmetric, iterations = 1, local iterations = 1, omega = 1.
      linear system matrix = precond matrix:
      Mat Object: 4 MPI processes
        type: mpiaijkokkos
        rows=95207, cols=95207
        total: nonzeros=3033895, allocated nonzeros=3033895
        total number of mallocs used during MatSetValues calls=0
          not using I-node (on process 0) routines
  Up solver (post-smoother) same as down solver (pre-smoother)
  Down solver (pre-smoother) on level 3 -------------------------------
    KSP Object: (mg_levels_3_) 4 MPI processes
      type: chebyshev
        eigenvalue estimates used:  min = 0.139009, max = 1.5291
        eigenvalues estimate via gmres min 0.0287622, max 1.39009
        eigenvalues estimated using gmres with translations  [0. 0.1; 0. 1.1]
        KSP Object: (mg_levels_3_esteig_) 4 MPI processes
          type: gmres
            restart=30, using Classical (unmodified) Gram-Schmidt Orthogonalization with no iterative refinement
            happy breakdown tolerance 1e-30
          maximum iterations=10, initial guess is zero
          tolerances:  relative=1e-12, absolute=1e-50, divergence=10000.
          left preconditioning
          using PRECONDITIONED norm type for convergence test
        estimating eigenvalues using noisy right hand side
      maximum iterations=2, nonzero initial guess
      tolerances:  relative=1e-05, absolute=1e-50, divergence=10000.
      left preconditioning
      using NONE norm type for convergence test
    PC Object: (mg_levels_3_) 4 MPI processes
      type: sor
        type = local_symmetric, iterations = 1, local iterations = 1, omega = 1.
      linear system matrix = precond matrix:
      Mat Object: 4 MPI processes
        type: mpiaijkokkos
        rows=1048576, cols=1048576
        total: nonzeros=7266304, allocated nonzeros=7266304
        total number of mallocs used during MatSetValues calls=0
  Up solver (post-smoother) same as down solver (pre-smoother)
  linear system matrix = precond matrix:
  Mat Object: 4 MPI processes
    type: mpiaijkokkos
    rows=1048576, cols=1048576
    total: nonzeros=7266304, allocated nonzeros=7266304
    total number of mallocs used during MatSetValues calls=0
KSP Object: 4 MPI processes
  type: cg
  maximum iterations=10000, initial guess is zero
  tolerances:  relative=1e-05, absolute=1e-50, divergence=10000.
  left preconditioning
  using PRECONDITIONED norm type for convergence test
PC Object: 4 MPI processes
  type: gamg
    type is MULTIPLICATIVE, levels=4 cycles=v
      Cycles per PCApply=1
      Using externally compute Galerkin coarse grid matrices
      GAMG specific options
        Threshold for dropping small values in graph on each level =   -0.05   -0.05   -0.05   -0.05  
        Threshold scaling factor for each level not specified = 1.
        AGG specific options
          Symmetric graph false
          Number of levels to square graph 10
          Number smoothing steps 1
        Complexity:    grid = 1.42799
  Coarse grid solver -- level -------------------------------
    KSP Object: (mg_coarse_) 4 MPI processes
      type: preonly
      maximum iterations=10000, initial guess is zero
      tolerances:  relative=1e-05, absolute=1e-50, divergence=10000.
      left preconditioning
      using NONE norm type for convergence test
    PC Object: (mg_coarse_) 4 MPI processes
      type: bjacobi
        number of blocks = 4
        Local solver information for first block is in the following KSP and PC objects on rank 0:
        Use -mg_coarse_ksp_view ::ascii_info_detail to display information for all blocks
      KSP Object: (mg_coarse_sub_) 1 MPI processes
        type: preonly
        maximum iterations=1, initial guess is zero
        tolerances:  relative=1e-05, absolute=1e-50, divergence=10000.
        left preconditioning
        using NONE norm type for convergence test
      PC Object: (mg_coarse_sub_) 1 MPI processes
        type: lu
          out-of-place factorization
          tolerance for zero pivot 2.22045e-14
          using diagonal shift on blocks to prevent zero pivot [INBLOCKS]
          matrix ordering: nd
          factor fill ratio given 5., needed 1.1828
            Factored matrix follows:
              Mat Object: 1 MPI processes
                type: seqaijkokkos
                rows=16, cols=16
                package used to perform factorization: kokkos
                total: nonzeros=220, allocated nonzeros=220
                  using I-node routines: found 5 nodes, limit used is 5
        linear system matrix = precond matrix:
        Mat Object: (mg_coarse_sub_) 1 MPI processes
          type: seqaijkokkos
          rows=16, cols=16
          total: nonzeros=186, allocated nonzeros=186
          total number of mallocs used during MatSetValues calls=0
            using I-node routines: found 11 nodes, limit used is 5
      linear system matrix = precond matrix:
      Mat Object: 4 MPI processes
        type: mpiaijkokkos
        rows=16, cols=16
        total: nonzeros=186, allocated nonzeros=186
        total number of mallocs used during MatSetValues calls=0
          using I-node (on process 0) routines: found 11 nodes, limit used is 5
  Down solver (pre-smoother) on level 1 -------------------------------
    KSP Object: (mg_levels_1_) 4 MPI processes
      type: chebyshev
        eigenvalue estimates used:  min = 0.133228, max = 1.4655
        eigenvalues estimate via gmres min 0.285788, max 1.33228
        eigenvalues estimated using gmres with translations  [0. 0.1; 0. 1.1]
        KSP Object: (mg_levels_1_esteig_) 4 MPI processes
          type: gmres
            restart=30, using Classical (unmodified) Gram-Schmidt Orthogonalization with no iterative refinement
            happy breakdown tolerance 1e-30
          maximum iterations=10, initial guess is zero
          tolerances:  relative=1e-12, absolute=1e-50, divergence=10000.
          left preconditioning
          using PRECONDITIONED norm type for convergence test
        estimating eigenvalues using noisy right hand side
      maximum iterations=2, nonzero initial guess
      tolerances:  relative=1e-05, absolute=1e-50, divergence=10000.
      left preconditioning
      using NONE norm type for convergence test
    PC Object: (mg_levels_1_) 4 MPI processes
      type: sor
        type = local_symmetric, iterations = 1, local iterations = 1, omega = 1.
      linear system matrix = precond matrix:
      Mat Object: 4 MPI processes
        type: mpiaijkokkos
        rows=1477, cols=1477
        total: nonzeros=75809, allocated nonzeros=75809
        total number of mallocs used during MatSetValues calls=0
          not using I-node (on process 0) routines
  Up solver (post-smoother) same as down solver (pre-smoother)
  Down solver (pre-smoother) on level 2 -------------------------------
    KSP Object: (mg_levels_2_) 4 MPI processes
      type: chebyshev
        eigenvalue estimates used:  min = 0.135914, max = 1.49505
        eigenvalues estimate via gmres min 0.0401755, max 1.35914
        eigenvalues estimated using gmres with translations  [0. 0.1; 0. 1.1]
        KSP Object: (mg_levels_2_esteig_) 4 MPI processes
          type: gmres
            restart=30, using Classical (unmodified) Gram-Schmidt Orthogonalization with no iterative refinement
            happy breakdown tolerance 1e-30
          maximum iterations=10, initial guess is zero
          tolerances:  relative=1e-12, absolute=1e-50, divergence=10000.
          left preconditioning
          using PRECONDITIONED norm type for convergence test
        estimating eigenvalues using noisy right hand side
      maximum iterations=2, nonzero initial guess
      tolerances:  relative=1e-05, absolute=1e-50, divergence=10000.
      left preconditioning
      using NONE norm type for convergence test
    PC Object: (mg_levels_2_) 4 MPI processes
      type: sor
        type = local_symmetric, iterations = 1, local iterations = 1, omega = 1.
      linear system matrix = precond matrix:
      Mat Object: 4 MPI processes
        type: mpiaijkokkos
        rows=95207, cols=95207
        total: nonzeros=3033895, allocated nonzeros=3033895
        total number of mallocs used during MatSetValues calls=0
          not using I-node (on process 0) routines
  Up solver (post-smoother) same as down solver (pre-smoother)
  Down solver (pre-smoother) on level 3 -------------------------------
    KSP Object: (mg_levels_3_) 4 MPI processes
      type: chebyshev
        eigenvalue estimates used:  min = 0.139009, max = 1.5291
        eigenvalues estimate via gmres min 0.0287622, max 1.39009
        eigenvalues estimated using gmres with translations  [0. 0.1; 0. 1.1]
        KSP Object: (mg_levels_3_esteig_) 4 MPI processes
          type: gmres
            restart=30, using Classical (unmodified) Gram-Schmidt Orthogonalization with no iterative refinement
            happy breakdown tolerance 1e-30
          maximum iterations=10, initial guess is zero
          tolerances:  relative=1e-12, absolute=1e-50, divergence=10000.
          left preconditioning
          using PRECONDITIONED norm type for convergence test
        estimating eigenvalues using noisy right hand side
      maximum iterations=2, nonzero initial guess
      tolerances:  relative=1e-05, absolute=1e-50, divergence=10000.
      left preconditioning
      using NONE norm type for convergence test
    PC Object: (mg_levels_3_) 4 MPI processes
      type: sor
        type = local_symmetric, iterations = 1, local iterations = 1, omega = 1.
      linear system matrix = precond matrix:
      Mat Object: 4 MPI processes
        type: mpiaijkokkos
        rows=1048576, cols=1048576
        total: nonzeros=7266304, allocated nonzeros=7266304
        total number of mallocs used during MatSetValues calls=0
  Up solver (post-smoother) same as down solver (pre-smoother)
  linear system matrix = precond matrix:
  Mat Object: 4 MPI processes
    type: mpiaijkokkos
    rows=1048576, cols=1048576
    total: nonzeros=7266304, allocated nonzeros=7266304
    total number of mallocs used during MatSetValues calls=0
**************************************** ***********************************************************************************************************************
***                                WIDEN YOUR WINDOW TO 160 CHARACTERS.  Use 'enscript -r -fCourier9' to print this document                                 ***
****************************************************************************************************************************************************************

------------------------------------------------------------------ PETSc Performance Summary: -------------------------------------------------------------------

./poisson3d on a  named LAPTOP-CDJT2P3R with 4 processors, by sajid Tue Feb  8 14:37:20 2022
Using Petsc Development GIT revision: f351d5494b5462f62c419e00645ac2e477b88cae  GIT Date: 2022-02-08 15:08:19 +0000

                         Max       Max/Min     Avg       Total
Time (sec):           4.775e+00     1.000   4.775e+00
Objects:              4.550e+02     1.004   4.535e+02
Flop:                 5.563e+08     1.003   5.558e+08  2.223e+09
Flop/sec:             1.165e+08     1.003   1.164e+08  4.656e+08
MPI Messages:         6.115e+02     1.938   4.730e+02  1.892e+03
MPI Message Lengths:  1.353e+07     2.000   2.145e+04  4.058e+07
MPI Reductions:       5.150e+02     1.000

Flop counting convention: 1 flop = 1 real number operation of type (multiply/divide/add/subtract)
                            e.g., VecAXPY() for real vectors of length N --> 2N flop
                            and VecAXPY() for complex vectors of length N --> 8N flop

Summary of Stages:   ----- Time ------  ----- Flop ------  --- Messages ---  -- Message Lengths --  -- Reductions --
                        Avg     %Total     Avg     %Total    Count   %Total     Avg         %Total    Count   %Total
 0:      Main Stage: 4.3017e+00  90.1%  1.1804e+09  53.1%  1.352e+03  71.5%  2.550e+04       84.9%  4.420e+02  85.8%
 1:    linear-solve: 4.7309e-01   9.9%  1.0430e+09  46.9%  5.400e+02  28.5%  1.131e+04       15.1%  5.500e+01  10.7%

------------------------------------------------------------------------------------------------------------------------
See the 'Profiling' chapter of the users' manual for details on interpreting output.
Phase summary info:
   Count: number of times phase was executed
   Time and Flop: Max - maximum over all processors
                  Ratio - ratio of maximum to minimum over all processors
   Mess: number of messages sent
   AvgLen: average message length (bytes)
   Reduct: number of global reductions
   Global: entire computation
   Stage: stages of a computation. Set stages with PetscLogStagePush() and PetscLogStagePop().
      %T - percent time in this phase         %F - percent flop in this phase
      %M - percent messages in this phase     %L - percent message lengths in this phase
      %R - percent reductions in this phase
   Total Mflop/s: 10e-6 * (sum of flop over all processors)/(max time over all processors)
   GPU Mflop/s: 10e-6 * (sum of flop on GPU over all processors)/(max GPU time over all processors)
   CpuToGpu Count: total number of CPU to GPU copies per processor
   CpuToGpu Size (Mbytes): 10e-6 * (total size of CPU to GPU copies per processor)
   GpuToCpu Count: total number of GPU to CPU copies per processor
   GpuToCpu Size (Mbytes): 10e-6 * (total size of GPU to CPU copies per processor)
   GPU %F: percent flops on GPU in this event
------------------------------------------------------------------------------------------------------------------------
Event                Count      Time (sec)     Flop                              --- Global ---  --- Stage ----  Total   GPU    - CpuToGpu -   - GpuToCpu - GPU
                   Max Ratio  Max     Ratio   Max  Ratio  Mess   AvgLen  Reduct  %T %F %M %L %R  %T %F %M %L %R Mflop/s Mflop/s Count   Size   Count   Size  %F
---------------------------------------------------------------------------------------------------------------------------------------------------------------

--- Event Stage 0: Main Stage

BuildTwoSided         58 1.0 1.1477e-01 3.7 0.00e+00 0.0 1.8e+02 4.0e+00 5.8e+01  2  0 10  0 11   2  0 14  0 13     0       0      0 0.00e+00    0 0.00e+00  0
BuildTwoSidedF        29 1.0 1.0018e-0144.5 0.00e+00 0.0 3.2e+01 4.7e+03 2.9e+01  1  0  2  0  6   1  0  2  0  7     0       0      0 0.00e+00    0 0.00e+00  0
MatMult               72 1.0 1.7433e-01 1.1 1.25e+08 1.0 4.7e+02 1.5e+04 3.0e+00  3 22 25 17  1   4 42 35 20  1  2857       0      0 0.00e+00    0 0.00e+00 100
MatMultAdd             3 1.0 5.3818e-03 1.0 2.01e+06 1.0 1.5e+01 3.0e+03 0.0e+00  0  0  1  0  0   0  1  1  0  0  1492    1536      0 0.00e+00    0 0.00e+00 100
MatMultTranspose       3 1.0 6.3040e-03 2.6 2.01e+06 1.0 2.1e+01 2.2e+03 1.0e+00  0  0  1  0  0   0  1  2  0  0  1275    2872      0 0.00e+00    0 0.00e+00 100
MatSolve               1 0.0 3.1000e-06 0.0 4.24e+02 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0   137       0      0 0.00e+00    0 0.00e+00  0
MatSOR                45 1.0 1.9288e-01 1.1 7.75e+07 1.0 0.0e+00 0.0e+00 0.0e+00  4 14  0  0  0   4 26  0  0  0  1605       0      0 0.00e+00    0 0.00e+00  0
MatLUFactorSym         1 1.0 2.3500e-05 1.2 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0       0      0 0.00e+00    0 0.00e+00  0
MatLUFactorNum         1 1.0 6.5000e-06 5.0 1.81e+03 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0   278       0      0 0.00e+00    0 0.00e+00  0
MatConvert             3 1.0 3.6411e-02 1.1 0.00e+00 0.0 3.6e+01 3.9e+03 3.0e+00  1  0  2  0  1   1  0  3  0  1     0       0      0 0.00e+00    0 0.00e+00  0
MatScale               6 1.0 5.8499e-03 1.1 2.01e+06 1.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  1  0  0  0  1373       0      0 0.00e+00    0 0.00e+00 50
MatResidual            3 1.0 9.9451e-03 1.3 5.77e+06 1.0 1.8e+01 1.6e+04 0.0e+00  0  1  1  1  0   0  2  1  1  0  2317       0      0 0.00e+00    0 0.00e+00 100
MatAssemblyBegin      81 1.0 9.4017e-0247.5 0.00e+00 0.0 3.2e+01 4.7e+03 1.0e+01  1  0  2  0  2   1  0  2  0  2     0       0      0 0.00e+00    0 0.00e+00  0
MatAssemblyEnd        81 1.0 2.2096e-01 1.5 0.00e+00 0.0 0.0e+00 0.0e+00 6.0e+01  4  0  0  0 12   4  0  0  0 14     0       0      0 0.00e+00    0 0.00e+00  0
MatGetRowIJ            1 0.0 3.5000e-06 0.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0       0      0 0.00e+00    0 0.00e+00  0
MatCreateSubMat        2 1.0 1.0326e-03 1.0 0.00e+00 0.0 1.5e+01 1.4e+02 2.8e+01  0  0  1  0  5   0  0  1  0  6     0       0      0 0.00e+00    0 0.00e+00  0
MatGetOrdering         1 0.0 4.8600e-05 0.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0       0      0 0.00e+00    0 0.00e+00  0
MatCoarsen             3 1.0 4.2983e-02 1.3 0.00e+00 0.0 1.1e+02 1.3e+04 9.0e+00  1  0  6  4  2   1  0  8  4  2     0       0      0 0.00e+00    0 0.00e+00  0
MatView                7 1.4 4.2430e-04 2.2 0.00e+00 0.0 0.0e+00 0.0e+00 5.0e+00  0  0  0  0  1   0  0  0  0  1     0       0      0 0.00e+00    0 0.00e+00  0
MatAXPY                3 1.0 6.3706e-02 1.0 2.86e+05 1.0 0.0e+00 0.0e+00 3.0e+00  1  0  0  0  1   1  0  0  0  1    18       0      0 0.00e+00    0 0.00e+00  0
MatMatMultSym          3 1.0 2.5677e-01 1.0 0.00e+00 0.0 1.1e+02 6.5e+03 2.1e+01  5  0  6  2  4   6  0  8  2  5     0       0      0 0.00e+00    0 0.00e+00  0
MatMatMultNum          3 1.0 2.2700e-05 5.4 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0       0      0 0.00e+00    0 0.00e+00  0
MatPtAPSymbolic        3 1.0 7.2889e-01 1.0 0.00e+00 0.0 2.5e+02 1.5e+04 2.7e+01 15  0 13 10  5  17  0 19 11  6     0       0      0 0.00e+00    0 0.00e+00  0
MatPtAPNumeric         3 1.0 5.3000e-06 1.1 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0       0      0 0.00e+00    0 0.00e+00  0
MatTrnMatMultSym       3 1.0 1.7381e+00 1.0 0.00e+00 0.0 1.1e+02 1.6e+05 2.1e+01 36  0  6 42  4  40  0  8 50  5     0       0      0 0.00e+00    0 0.00e+00  0
MatGetLocalMat         9 1.0 8.5133e-02 1.1 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  2  0  0  0  0   2  0  0  0  0     0       0      0 0.00e+00    0 0.00e+00  0
DMCreateMat            1 1.0 2.4135e-01 1.0 0.00e+00 0.0 0.0e+00 0.0e+00 7.0e+00  5  0  0  0  1   6  0  0  0  2     0       0      0 0.00e+00    0 0.00e+00  0
SFSetGraph            36 1.0 4.2400e-04 1.2 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0       0      0 0.00e+00    0 0.00e+00  0
SFSetUp               29 1.0 4.8815e-02 1.8 0.00e+00 0.0 3.4e+02 1.8e+04 2.9e+01  1  0 18 15  6   1  0 25 18  7     0       0      0 0.00e+00    0 0.00e+00  0
SFBcastBegin          30 1.0 7.9370e-04 1.4 0.00e+00 0.0 1.8e+02 2.0e+04 0.0e+00  0  0 10  9  0   0  0 13 10  0     0       0      0 0.00e+00    0 0.00e+00  0
SFBcastEnd            30 1.0 1.9861e-02 2.1 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0       0      0 0.00e+00    0 0.00e+00  0
SFReduceBegin         12 1.0 2.6490e-04 1.2 0.00e+00 0.0 7.2e+01 1.9e+05 0.0e+00  0  0  4 34  0   0  0  5 40  0     0       0      0 0.00e+00    0 0.00e+00  0
SFReduceEnd           12 1.0 3.7232e-03 1.1 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0       0      0 0.00e+00    0 0.00e+00  0
SFPack               142 1.0 1.1699e-03 4.1 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0       0      0 0.00e+00    0 0.00e+00  0
SFUnpack             142 1.0 1.1390e-04 1.4 1.89e+03 2.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0    50       0      0 0.00e+00    0 0.00e+00  0
VecView                2 1.0 2.1857e-01 1.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  5  0  0  0  0   5  0  0  0  0     0       0      0 0.00e+00    0 0.00e+00  0
VecMDot               30 1.0 9.2085e-02 2.4 0.00e+00 0.0 0.0e+00 0.0e+00 3.0e+01  1  0  0  0  6   1  0  0  0  7     0       0      0 0.00e+00    0 0.00e+00  0
VecTDot               63 1.0 4.2062e-02 2.9 1.20e+07 1.0 0.0e+00 0.0e+00 6.3e+01  0  2  0  0 12   1  4  0  0 14  1144    3488      0 0.00e+00    0 0.00e+00 100
VecNorm               34 1.0 3.4942e-02 5.5 6.83e+06 1.0 0.0e+00 0.0e+00 3.4e+01  0  1  0  0  7   0  2  0  0  8   781    4425      0 0.00e+00    0 0.00e+00 100
VecScale              37 1.0 8.9161e-03 1.5 4.20e+06 1.0 0.0e+00 0.0e+00 0.0e+00  0  1  0  0  0   0  1  0  0  0  1883    1905      0 0.00e+00    0 0.00e+00 100
VecCopy               19 1.0 6.8710e-03 1.2 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0       0      0 0.00e+00    0 0.00e+00  0
VecSet                47 1.0 4.1322e-03 1.5 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0       0      0 0.00e+00    0 0.00e+00  0
VecAXPY               63 1.0 2.2165e-02 2.1 1.20e+07 1.0 0.0e+00 0.0e+00 0.0e+00  0  2  0  0  0   0  4  0  0  0  2170    2200      0 0.00e+00    0 0.00e+00 100
VecAYPX               45 1.0 1.3298e-02 1.6 8.59e+06 1.0 0.0e+00 0.0e+00 0.0e+00  0  2  0  0  0   0  3  0  0  0  2584    2617      0 0.00e+00    0 0.00e+00 100
VecAXPBYCZ             6 1.0 2.1450e-03 1.2 2.86e+06 1.0 0.0e+00 0.0e+00 0.0e+00  0  1  0  0  0   0  1  0  0  0  5339    5378      0 0.00e+00    0 0.00e+00 100
VecMAXPY              33 1.0 4.8749e-02 2.0 3.72e+07 1.0 0.0e+00 0.0e+00 0.0e+00  1  7  0  0  0   1 13  0  0  0  3054       0      0 0.00e+00    0 0.00e+00 100
VecAssemblyBegin      20 1.0 6.9876e-03 7.0 0.00e+00 0.0 0.0e+00 0.0e+00 1.9e+01  0  0  0  0  4   0  0  0  0  4     0       0      0 0.00e+00    0 0.00e+00  0
VecAssemblyEnd        20 1.0 4.9600e-05 1.2 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0       0      0 0.00e+00    0 0.00e+00  0
VecPointwiseMult      33 1.0 1.2068e-02 1.4 3.15e+06 1.0 0.0e+00 0.0e+00 0.0e+00  0  1  0  0  0   0  1  0  0  0  1044    1050      0 0.00e+00    0 0.00e+00 100
VecScatterBegin      100 1.0 6.9179e-03 1.2 0.00e+00 0.0 6.8e+02 1.6e+04 8.0e+00  0  0 36 27  2   0  0 50 32  2     0       0      0 0.00e+00    0 0.00e+00  0
VecScatterEnd        100 1.0 1.2936e-02 4.4 1.89e+03 2.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0       0      0 0.00e+00    0 0.00e+00  0
VecSetRandom           3 1.0 8.3425e-03 1.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0       0      0 0.00e+00    0 0.00e+00  0
VecNormalize          33 1.0 3.8154e-02 3.0 9.45e+06 1.0 0.0e+00 0.0e+00 3.3e+01  1  2  0  0  6   1  3  0  0  7   991    3177      0 0.00e+00    0 0.00e+00 100
KSPSetUp               9 1.0 3.6849e-01 1.0 1.56e+08 1.0 1.8e+02 1.6e+04 7.1e+01  8 28 10  7 14   8 53 13  8 16  1693       0      0 0.00e+00    0 0.00e+00 64
KSPSolve               1 1.0 1.0675e-01 1.1 5.22e+07 1.0 1.1e+02 1.1e+04 3.0e+00  2  9  6  3  1   2 18  8  4  1  1954       0      0 0.00e+00    0 0.00e+00 61
KSPGMRESOrthog        30 1.0 1.1222e-01 1.5 3.15e+07 1.0 0.0e+00 0.0e+00 3.0e+01  2  6  0  0  6   2 11  0  0  7  1123       0      0 0.00e+00    0 0.00e+00 100
PCGAMGGraph_AGG        3 1.0 4.1559e-02 1.1 0.00e+00 0.0 3.6e+01 3.9e+03 3.0e+00  1  0  2  0  1   1  0  3  0  1     0       0      0 0.00e+00    0 0.00e+00  0
PCGAMGCoarse_AGG       3 1.0 1.8723e+00 1.0 0.00e+00 0.0 3.4e+02 6.3e+04 5.7e+01 39  0 18 53 11  43  0 25 62 13     0       0      0 0.00e+00    0 0.00e+00  0
PCGAMGProl_AGG         3 1.0 1.0724e-01 1.1 0.00e+00 0.0 6.8e+01 1.9e+04 4.5e+01  2  0  4  3  9   2  0  5  4 10     0       0      0 0.00e+00    0 0.00e+00  0
PCGAMGPOpt_AGG         3 1.0 4.8176e-01 1.0 8.61e+07 1.0 3.2e+02 1.1e+04 1.1e+02 10 15 17  9 22  11 29 24 11 26   714       0      0 0.00e+00    0 0.00e+00 98
GAMG: createProl       3 1.0 2.4939e+00 1.0 8.61e+07 1.0 7.7e+02 3.4e+04 2.2e+02 52 15 41 65 43  58 29 57 77 50   138       0      0 0.00e+00    0 0.00e+00 98
  Graph                6 1.0 4.1539e-02 1.1 0.00e+00 0.0 3.6e+01 3.9e+03 3.0e+00  1  0  2  0  1   1  0  3  0  1     0       0      0 0.00e+00    0 0.00e+00  0
  MIS/Agg              3 1.0 4.3061e-02 1.3 0.00e+00 0.0 1.1e+02 1.3e+04 9.0e+00  1  0  6  4  2   1  0  8  4  2     0       0      0 0.00e+00    0 0.00e+00  0
  SA: col data         3 1.0 2.5204e-02 1.0 0.00e+00 0.0 3.6e+01 3.2e+04 1.8e+01  1  0  2  3  3   1  0  3  3  4     0       0      0 0.00e+00    0 0.00e+00  0
  SA: frmProl0         3 1.0 6.7292e-02 1.0 0.00e+00 0.0 3.2e+01 4.7e+03 1.5e+01  1  0  2  0  3   2  0  2  0  3     0       0      0 0.00e+00    0 0.00e+00  0
  SA: smooth           3 1.0 3.3273e-01 1.0 2.30e+06 1.0 1.1e+02 6.5e+03 3.0e+01  7  0  6  2  6   8  1  8  2  7    28       0      0 0.00e+00    0 0.00e+00 44
GAMG: partLevel        3 1.0 7.3095e-01 1.0 0.00e+00 0.0 2.9e+02 1.3e+04 8.0e+01 15  0 15 10 16  17  0 21 11 18     0       0      0 0.00e+00    0 0.00e+00  0
  repartition          1 1.0 1.9616e-03 1.0 0.00e+00 0.0 3.6e+01 6.8e+01 5.3e+01  0  0  2  0 10   0  0  3  0 12     0       0      0 0.00e+00    0 0.00e+00  0
  Invert-Sort          1 1.0 8.8700e-05 1.1 0.00e+00 0.0 0.0e+00 0.0e+00 6.0e+00  0  0  0  0  1   0  0  0  0  1     0       0      0 0.00e+00    0 0.00e+00  0
  Move A               1 1.0 6.1580e-04 1.1 0.00e+00 0.0 1.5e+01 1.4e+02 1.5e+01  0  0  1  0  3   0  0  1  0  3     0       0      0 0.00e+00    0 0.00e+00  0
  Move P               1 1.0 7.0840e-04 1.1 0.00e+00 0.0 0.0e+00 0.0e+00 1.6e+01  0  0  0  0  3   0  0  0  0  4     0       0      0 0.00e+00    0 0.00e+00  0
PCGAMG Squ l00         1 1.0 1.0381e+00 1.0 0.00e+00 0.0 3.6e+01 7.9e+04 7.0e+00 22  0  2  7  1  24  0  3  8  2     0       0      0 0.00e+00    0 0.00e+00  0
PCGAMG Gal l00         1 1.0 6.1581e-01 1.0 0.00e+00 0.0 8.4e+01 3.3e+04 9.0e+00 13  0  4  7  2  14  0  6  8  2     0       0      0 0.00e+00    0 0.00e+00  0
PCGAMG Opt l00         1 1.0 2.2416e-01 1.0 0.00e+00 0.0 3.6e+01 1.4e+04 7.0e+00  5  0  2  1  1   5  0  3  1  2     0       0      0 0.00e+00    0 0.00e+00  0
PCGAMG Squ l01         1 1.0 6.7891e-01 1.0 0.00e+00 0.0 3.6e+01 3.5e+05 7.0e+00 14  0  2 31  1  16  0  3 37  2     0       0      0 0.00e+00    0 0.00e+00  0
PCGAMG Gal l01         1 1.0 1.1008e-01 1.0 0.00e+00 0.0 8.4e+01 1.2e+04 9.0e+00  2  0  4  3  2   3  0  6  3  2     0       0      0 0.00e+00    0 0.00e+00  0
PCGAMG Opt l01         1 1.0 3.0773e-02 1.0 0.00e+00 0.0 3.6e+01 5.6e+03 7.0e+00  1  0  2  0  1   1  0  3  1  2     0       0      0 0.00e+00    0 0.00e+00  0
PCGAMG Squ l02         1 1.0 2.2889e-02 1.0 0.00e+00 0.0 3.6e+01 4.7e+04 7.0e+00  0  0  2  4  1   1  0  3  5  2     0       0      0 0.00e+00    0 0.00e+00  0
PCGAMG Gal l02         1 1.0 3.1122e-03 1.0 0.00e+00 0.0 8.4e+01 6.4e+02 9.0e+00  0  0  4  0  2   0  0  6  0  2     0       0      0 0.00e+00    0 0.00e+00  0
PCGAMG Opt l02         1 1.0 1.9782e-03 1.0 0.00e+00 0.0 3.6e+01 4.2e+02 7.0e+00  0  0  2  0  1   0  0  3  0  2     0       0      0 0.00e+00    0 0.00e+00  0
PCSetUp                2 1.0 3.5885e+00 1.0 2.42e+08 1.0 1.2e+03 2.7e+04 3.8e+02 75 44 65 82 74  83 82 92 96 86   270       0      0 0.00e+00    0 0.00e+00 76
PCSetUpOnBlocks        1 1.0 9.2800e-05 1.4 1.81e+03 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0    19       0      0 0.00e+00    0 0.00e+00  0
PCApply                1 1.0 1.0525e-01 1.1 5.17e+07 1.0 1.1e+02 1.1e+04 1.0e+00  2  9  6  3  0   2 17  8  4  0  1962       0      0 0.00e+00    0 0.00e+00 60

--- Event Stage 1: linear-solve

MatMult               60 1.0 1.3498e-01 1.0 1.04e+08 1.0 3.6e+02 1.6e+04 0.0e+00  3 19 19 14  0  28 40 67 93  0  3075       0      0 0.00e+00    0 0.00e+00 100
MatMultAdd            15 1.0 2.7334e-02 1.1 1.01e+07 1.0 7.5e+01 3.0e+03 0.0e+00  1  2  4  1  0   6  4 14  4  0  1469    1510      0 0.00e+00    0 0.00e+00 100
MatMultTranspose      15 1.0 2.8124e-02 2.2 1.01e+07 1.0 7.5e+01 3.0e+03 0.0e+00  0  2  4  1  0   4  4 14  4  0  1429    3737      0 0.00e+00    0 0.00e+00 100
MatSolve               5 0.0 2.3900e-05 0.0 2.12e+03 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0    89       0      0 0.00e+00    0 0.00e+00  0
MatSOR                60 1.0 2.3125e-01 1.1 1.03e+08 1.0 0.0e+00 0.0e+00 0.0e+00  5 18  0  0  0  47 39  0  0  0  1778       0      0 0.00e+00    0 0.00e+00  0
MatResidual           15 1.0 3.9490e-02 1.1 2.89e+07 1.0 9.0e+01 1.6e+04 0.0e+00  1  5  5  3  0   8 11 17 23  0  2918       0      0 0.00e+00    0 0.00e+00 100
MatView               35 1.4 2.4592e-03 2.9 0.00e+00 0.0 0.0e+00 0.0e+00 2.5e+01  0  0  0  0  5   0  0  0  0 45     0       0      0 0.00e+00    0 0.00e+00  0
SFPack                90 1.0 7.2510e-04 5.3 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0       0      0 0.00e+00    0 0.00e+00  0
SFUnpack              90 1.0 9.2400e-05 1.3 9.44e+03 2.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0   308       0      0 0.00e+00    0 0.00e+00  0
VecNorm                5 1.0 2.1682e-02 8.3 2.62e+06 1.0 0.0e+00 0.0e+00 5.0e+00  0  0  0  0  1   2  1  0  0  9   484    4466      0 0.00e+00    0 0.00e+00 100
VecCopy               50 1.0 1.7830e-02 1.1 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   4  0  0  0  0     0       0      0 0.00e+00    0 0.00e+00  0
VecSet                35 1.0 5.1208e-03 1.1 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   1  0  0  0  0     0       0      0 0.00e+00    0 0.00e+00  0
VecAYPX               90 1.0 2.3938e-02 1.2 1.72e+07 1.0 0.0e+00 0.0e+00 0.0e+00  0  3  0  0  0   5  7  0  0  0  2871    2914      0 0.00e+00    0 0.00e+00 100
VecAXPBYCZ            30 1.0 8.3389e-03 1.1 1.43e+07 1.0 0.0e+00 0.0e+00 0.0e+00  0  3  0  0  0   2  5  0  0  0  6867    6920      0 0.00e+00    0 0.00e+00 100
VecScatterBegin       90 1.0 2.3191e-03 1.1 0.00e+00 0.0 5.1e+02 1.2e+04 0.0e+00  0  0 27 15  0   0  0 94100  0     0       0      0 0.00e+00    0 0.00e+00  0
VecScatterEnd         90 1.0 4.1450e-02 6.0 9.44e+03 2.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   4  0  0  0  0     1       0      0 0.00e+00    0 0.00e+00  0
KSPSolve               5 1.0 4.6864e-01 1.0 2.61e+08 1.0 5.1e+02 1.2e+04 1.0e+01 10 47 27 15  2  99100 94100 18  2226       0      0 0.00e+00    0 0.00e+00 61
PCSetUpOnBlocks        5 1.0 5.1000e-06 1.3 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0       0      0 0.00e+00    0 0.00e+00  0
PCApply                5 1.0 4.5792e-01 1.0 2.58e+08 1.0 5.1e+02 1.2e+04 0.0e+00  9 46 27 15  0  95 99 94100  0  2255       0      0 0.00e+00    0 0.00e+00 60
---------------------------------------------------------------------------------------------------------------------------------------------------------------

Memory usage is given in bytes:

Object Type          Creations   Destructions     Memory  Descendants' Mem.
Reports information only for process 0.

--- Event Stage 0: Main Stage

    Distributed Mesh     8              8        41408     0.
              Matrix    99             99    113359896     0.
      Matrix Coarsen     3              3         1872     0.
           Index Set    65             65      5763508     0.
   IS L to G Mapping     8              8      2149656     0.
   Star Forest Graph    52             52        60384     0.
     Discrete System     8              8         7680     0.
           Weak Form     8              8         4928     0.
              Vector   163            163     93320904     0.
       Krylov Solver    12             12       108048     0.
     DMKSP interface     1              1          656     0.
      Preconditioner    12             12        12116     0.
              Viewer     5              4         3312     0.
         PetscRandom     6              6         3972     0.

--- Event Stage 1: linear-solve

              Viewer     5              5         4200     0.
========================================================================================================================
Average time to get PetscTime(): 6e-08
Average time for MPI_Barrier(): 7.708e-05
Average time for zero size MPI_Send(): 3.2e-06
#PETSc Option Table entries:
-dm_mat_type aijkokkos
-dm_vec_type kokkos
-ksp_monitor
-ksp_type cg
-ksp_view
-log_view
-pc_gamg_agg_nsmooths 1
-pc_gamg_esteig_ksp_type cg
-pc_gamg_square_graph 10
-pc_gamg_threshold -0.05
-pc_type gamg
#End of PETSc Option Table entries
Compiled without FORTRAN kernels
Compiled with full precision matrices (default)
sizeof(short) 2 sizeof(int) 4 sizeof(long) 8 sizeof(void*) 8 sizeof(PetscScalar) 8 sizeof(PetscInt) 4
Configure options: --prefix=/home/sajid/packages/spack/opt/spack/linux-ubuntu20.04-zen2/clang-13.0.0/petsc-main-hmtporcjnnxb3wjlx3j75xj275pkwreb --with-ssl=0 --download-c2html=0 --download-sowing=0 --download-hwloc=0 CFLAGS="-O2 -march=znver2 -mtune=znver2" FFLAGS="-O2 -march=znver2 -mtune=znver2" CXXFLAGS="-O2 -march=znver2 -mtune=znver2 -stdlib=libc++" --with-cc=/home/sajid/packages/spack/opt/spack/linux-ubuntu20.04-zen2/clang-13.0.0/mpich-3.4.2-fizqettdbupbpgrurxak3vq64nz5jqss/bin/mpicc --with-cxx=/home/sajid/packages/spack/opt/spack/linux-ubuntu20.04-zen2/clang-13.0.0/mpich-3.4.2-fizqettdbupbpgrurxak3vq64nz5jqss/bin/mpic++ --with-fc=/home/sajid/packages/spack/opt/spack/linux-ubuntu20.04-zen2/clang-13.0.0/mpich-3.4.2-fizqettdbupbpgrurxak3vq64nz5jqss/bin/mpif90 --with-precision=double --with-scalar-type=real --with-shared-libraries=1 --with-debugging=0 --with-openmp=0 --with-64-bit-indices=0 COPTFLAGS= FOPTFLAGS= CXXOPTFLAGS= --with-blaslapack-lib=/home/sajid/packages/spack/opt/spack/linux-ubuntu20.04-zen2/clang-13.0.0/openblas-0.3.19-y57mcwqmkypntdviqqny2bknjcq5u3hl/lib/libopenblas.so --with-x=0 --with-clanguage=C --with-cuda=0 --with-hip=0 --with-metis=1 --with-metis-include=/home/sajid/packages/spack/opt/spack/linux-ubuntu20.04-zen2/clang-13.0.0/metis-5.1.0-bcj7iptdg36qwsxfvcxuv4gzm4rcdz6d/include --with-metis-lib=/home/sajid/packages/spack/opt/spack/linux-ubuntu20.04-zen2/clang-13.0.0/metis-5.1.0-bcj7iptdg36qwsxfvcxuv4gzm4rcdz6d/lib/libmetis.so --with-hypre=1 --with-hypre-include=/home/sajid/packages/spack/opt/spack/linux-ubuntu20.04-zen2/clang-13.0.0/hypre-develop-ygou5nh66e76l57yh5xinbyusrazuxrc/include --with-hypre-lib=/home/sajid/packages/spack/opt/spack/linux-ubuntu20.04-zen2/clang-13.0.0/hypre-develop-ygou5nh66e76l57yh5xinbyusrazuxrc/lib/libHYPRE.so --with-parmetis=1 --with-parmetis-include=/home/sajid/packages/spack/opt/spack/linux-ubuntu20.04-zen2/clang-13.0.0/parmetis-4.0.3-6rjlc7yzlksa5vlldsh65iu2uhm32kol/include --with-parmetis-lib=/home/sajid/packages/spack/opt/spack/linux-ubuntu20.04-zen2/clang-13.0.0/parmetis-4.0.3-6rjlc7yzlksa5vlldsh65iu2uhm32kol/lib/libparmetis.so --with-kokkos=1 --with-kokkos-dir=/home/sajid/packages/spack/opt/spack/linux-ubuntu20.04-zen2/clang-13.0.0/kokkos-3.5.00-mwffrxascvhceg4bprn3nyez4xn3vtqo --with-kokkos-kernels=1 --with-kokkos-kernels-dir=/home/sajid/packages/spack/opt/spack/linux-ubuntu20.04-zen2/clang-13.0.0/kokkos-kernels-3.5.00-ilzmu6zmvicgldct4yb4cfqt26mqxxsp --with-superlu_dist=1 --with-superlu_dist-include=/home/sajid/packages/spack/opt/spack/linux-ubuntu20.04-zen2/clang-13.0.0/superlu-dist-develop-g4cp4tbulw6yl3glysorqlgfsrqdfrvo/include --with-superlu_dist-lib=/home/sajid/packages/spack/opt/spack/linux-ubuntu20.04-zen2/clang-13.0.0/superlu-dist-develop-g4cp4tbulw6yl3glysorqlgfsrqdfrvo/lib/libsuperlu_dist.so --with-ptscotch=1 --with-ptscotch-include=/home/sajid/packages/spack/opt/spack/linux-ubuntu20.04-zen2/clang-13.0.0/scotch-6.1.1-gp3scxaylybflfgo4c52pmjtgs2jggjw/include --with-ptscotch-lib="/home/sajid/packages/spack/opt/spack/linux-ubuntu20.04-zen2/clang-13.0.0/scotch-6.1.1-gp3scxaylybflfgo4c52pmjtgs2jggjw/lib/libptesmumps.so /home/sajid/packages/spack/opt/spack/linux-ubuntu20.04-zen2/clang-13.0.0/scotch-6.1.1-gp3scxaylybflfgo4c52pmjtgs2jggjw/lib/libptscotch.so /home/sajid/packages/spack/opt/spack/linux-ubuntu20.04-zen2/clang-13.0.0/scotch-6.1.1-gp3scxaylybflfgo4c52pmjtgs2jggjw/lib/libptscotcherr.so /home/sajid/packages/spack/opt/spack/linux-ubuntu20.04-zen2/clang-13.0.0/scotch-6.1.1-gp3scxaylybflfgo4c52pmjtgs2jggjw/lib/libscotch.so /home/sajid/packages/spack/opt/spack/linux-ubuntu20.04-zen2/clang-13.0.0/scotch-6.1.1-gp3scxaylybflfgo4c52pmjtgs2jggjw/lib/libscotcherr.so /home/sajid/packages/spack/opt/spack/linux-ubuntu20.04-zen2/clang-13.0.0/zlib-1.2.11-hwlylittu23vvaixdrtuld7qt3a2h4uj/lib/libz.so" --with-suitesparse=0 --with-hdf5=1 --with-hdf5-include=/home/sajid/packages/spack/opt/spack/linux-ubuntu20.04-zen2/clang-13.0.0/hdf5-1.12.1-vo7rvdpj4kn7gmdkrcdh5pl7w2ouuriy/include --with-hdf5-lib="/home/sajid/packages/spack/opt/spack/linux-ubuntu20.04-zen2/clang-13.0.0/hdf5-1.12.1-vo7rvdpj4kn7gmdkrcdh5pl7w2ouuriy/lib/libhdf5_hl.so /home/sajid/packages/spack/opt/spack/linux-ubuntu20.04-zen2/clang-13.0.0/hdf5-1.12.1-vo7rvdpj4kn7gmdkrcdh5pl7w2ouuriy/lib/libhdf5.so" --with-zlib=1 --with-zlib-include=/home/sajid/packages/spack/opt/spack/linux-ubuntu20.04-zen2/clang-13.0.0/zlib-1.2.11-hwlylittu23vvaixdrtuld7qt3a2h4uj/include --with-zlib-lib=/home/sajid/packages/spack/opt/spack/linux-ubuntu20.04-zen2/clang-13.0.0/zlib-1.2.11-hwlylittu23vvaixdrtuld7qt3a2h4uj/lib/libz.so --with-mumps=0 --with-trilinos=0 --with-fftw=0 --with-valgrind=0 --with-gmp=0 --with-libpng=0 --with-giflib=0 --with-mpfr=0 --with-netcdf=0 --with-pnetcdf=0 --with-moab=0 --with-random123=0 --with-exodusii=0 --with-cgns=0 --with-memkind=0 --with-p4est=0 --with-saws=0 --with-yaml=0 --with-hwloc=0 --with-libjpeg=0 --with-scalapack=1 --with-scalapack-lib=/home/sajid/packages/spack/opt/spack/linux-ubuntu20.04-zen2/clang-13.0.0/netlib-scalapack-2.1.0-ne2gsmpz7l7njpz7vf452jegasxdjny3/lib/libscalapack.so --with-strumpack=1 --with-strumpack-include=/home/sajid/packages/spack/opt/spack/linux-ubuntu20.04-zen2/clang-13.0.0/strumpack-6.3.0-ov2ymtx2v4y6c6xn7kchhl2o6bcnruvt/include --with-strumpack-lib=/home/sajid/packages/spack/opt/spack/linux-ubuntu20.04-zen2/clang-13.0.0/strumpack-6.3.0-ov2ymtx2v4y6c6xn7kchhl2o6bcnruvt/lib/libstrumpack.so --with-mmg=0 --with-parmmg=0 --with-tetgen=0
-----------------------------------------
Libraries compiled on 2022-02-08 15:53:42 on LAPTOP-CDJT2P3R 
Machine characteristics: Linux-4.19.128-microsoft-standard-x86_64-with-glibc2.31
Using PETSc directory: /home/sajid/packages/spack/opt/spack/linux-ubuntu20.04-zen2/clang-13.0.0/petsc-main-hmtporcjnnxb3wjlx3j75xj275pkwreb
Using PETSc arch: 
-----------------------------------------

Using C compiler: /home/sajid/packages/spack/opt/spack/linux-ubuntu20.04-zen2/clang-13.0.0/mpich-3.4.2-fizqettdbupbpgrurxak3vq64nz5jqss/bin/mpicc -O2 -march=znver2 -mtune=znver2 -fPIC   
Using Fortran compiler: /home/sajid/packages/spack/opt/spack/linux-ubuntu20.04-zen2/clang-13.0.0/mpich-3.4.2-fizqettdbupbpgrurxak3vq64nz5jqss/bin/mpif90 -O2 -march=znver2 -mtune=znver2 -fPIC     
-----------------------------------------

Using include paths: -I/home/sajid/packages/spack/opt/spack/linux-ubuntu20.04-zen2/clang-13.0.0/petsc-main-hmtporcjnnxb3wjlx3j75xj275pkwreb/include -I/home/sajid/packages/spack/opt/spack/linux-ubuntu20.04-zen2/clang-13.0.0/hypre-develop-ygou5nh66e76l57yh5xinbyusrazuxrc/include -I/home/sajid/packages/spack/opt/spack/linux-ubuntu20.04-zen2/clang-13.0.0/strumpack-6.3.0-ov2ymtx2v4y6c6xn7kchhl2o6bcnruvt/include -I/home/sajid/packages/spack/opt/spack/linux-ubuntu20.04-zen2/clang-13.0.0/superlu-dist-develop-g4cp4tbulw6yl3glysorqlgfsrqdfrvo/include -I/home/sajid/packages/spack/opt/spack/linux-ubuntu20.04-zen2/clang-13.0.0/kokkos-kernels-3.5.00-ilzmu6zmvicgldct4yb4cfqt26mqxxsp/include -I/home/sajid/packages/spack/opt/spack/linux-ubuntu20.04-zen2/clang-13.0.0/kokkos-3.5.00-mwffrxascvhceg4bprn3nyez4xn3vtqo/include -I/home/sajid/packages/spack/opt/spack/linux-ubuntu20.04-zen2/clang-13.0.0/scotch-6.1.1-gp3scxaylybflfgo4c52pmjtgs2jggjw/include -I/home/sajid/packages/spack/opt/spack/linux-ubuntu20.04-zen2/clang-13.0.0/hdf5-1.12.1-vo7rvdpj4kn7gmdkrcdh5pl7w2ouuriy/include -I/home/sajid/packages/spack/opt/spack/linux-ubuntu20.04-zen2/clang-13.0.0/parmetis-4.0.3-6rjlc7yzlksa5vlldsh65iu2uhm32kol/include -I/home/sajid/packages/spack/opt/spack/linux-ubuntu20.04-zen2/clang-13.0.0/metis-5.1.0-bcj7iptdg36qwsxfvcxuv4gzm4rcdz6d/include -I/home/sajid/packages/spack/opt/spack/linux-ubuntu20.04-zen2/clang-13.0.0/zlib-1.2.11-hwlylittu23vvaixdrtuld7qt3a2h4uj/include
-----------------------------------------

Using C linker: /home/sajid/packages/spack/opt/spack/linux-ubuntu20.04-zen2/clang-13.0.0/mpich-3.4.2-fizqettdbupbpgrurxak3vq64nz5jqss/bin/mpicc
Using Fortran linker: /home/sajid/packages/spack/opt/spack/linux-ubuntu20.04-zen2/clang-13.0.0/mpich-3.4.2-fizqettdbupbpgrurxak3vq64nz5jqss/bin/mpif90
Using libraries: -Wl,-rpath,/home/sajid/packages/spack/opt/spack/linux-ubuntu20.04-zen2/clang-13.0.0/petsc-main-hmtporcjnnxb3wjlx3j75xj275pkwreb/lib -L/home/sajid/packages/spack/opt/spack/linux-ubuntu20.04-zen2/clang-13.0.0/petsc-main-hmtporcjnnxb3wjlx3j75xj275pkwreb/lib -lpetsc -Wl,-rpath,/home/sajid/packages/spack/opt/spack/linux-ubuntu20.04-zen2/clang-13.0.0/hypre-develop-ygou5nh66e76l57yh5xinbyusrazuxrc/lib -L/home/sajid/packages/spack/opt/spack/linux-ubuntu20.04-zen2/clang-13.0.0/hypre-develop-ygou5nh66e76l57yh5xinbyusrazuxrc/lib -Wl,-rpath,/home/sajid/packages/spack/opt/spack/linux-ubuntu20.04-zen2/clang-13.0.0/strumpack-6.3.0-ov2ymtx2v4y6c6xn7kchhl2o6bcnruvt/lib -L/home/sajid/packages/spack/opt/spack/linux-ubuntu20.04-zen2/clang-13.0.0/strumpack-6.3.0-ov2ymtx2v4y6c6xn7kchhl2o6bcnruvt/lib -Wl,-rpath,/home/sajid/packages/spack/opt/spack/linux-ubuntu20.04-zen2/clang-13.0.0/netlib-scalapack-2.1.0-ne2gsmpz7l7njpz7vf452jegasxdjny3/lib -L/home/sajid/packages/spack/opt/spack/linux-ubuntu20.04-zen2/clang-13.0.0/netlib-scalapack-2.1.0-ne2gsmpz7l7njpz7vf452jegasxdjny3/lib -Wl,-rpath,/home/sajid/packages/spack/opt/spack/linux-ubuntu20.04-zen2/clang-13.0.0/superlu-dist-develop-g4cp4tbulw6yl3glysorqlgfsrqdfrvo/lib -L/home/sajid/packages/spack/opt/spack/linux-ubuntu20.04-zen2/clang-13.0.0/superlu-dist-develop-g4cp4tbulw6yl3glysorqlgfsrqdfrvo/lib -Wl,-rpath,/home/sajid/packages/spack/opt/spack/linux-ubuntu20.04-zen2/clang-13.0.0/kokkos-kernels-3.5.00-ilzmu6zmvicgldct4yb4cfqt26mqxxsp/lib -L/home/sajid/packages/spack/opt/spack/linux-ubuntu20.04-zen2/clang-13.0.0/kokkos-kernels-3.5.00-ilzmu6zmvicgldct4yb4cfqt26mqxxsp/lib -Wl,-rpath,/home/sajid/packages/spack/opt/spack/linux-ubuntu20.04-zen2/clang-13.0.0/kokkos-3.5.00-mwffrxascvhceg4bprn3nyez4xn3vtqo/lib -L/home/sajid/packages/spack/opt/spack/linux-ubuntu20.04-zen2/clang-13.0.0/kokkos-3.5.00-mwffrxascvhceg4bprn3nyez4xn3vtqo/lib -Wl,-rpath,/home/sajid/packages/spack/opt/spack/linux-ubuntu20.04-zen2/clang-13.0.0/openblas-0.3.19-y57mcwqmkypntdviqqny2bknjcq5u3hl/lib -L/home/sajid/packages/spack/opt/spack/linux-ubuntu20.04-zen2/clang-13.0.0/openblas-0.3.19-y57mcwqmkypntdviqqny2bknjcq5u3hl/lib -Wl,-rpath,/home/sajid/packages/spack/opt/spack/linux-ubuntu20.04-zen2/clang-13.0.0/scotch-6.1.1-gp3scxaylybflfgo4c52pmjtgs2jggjw/lib -L/home/sajid/packages/spack/opt/spack/linux-ubuntu20.04-zen2/clang-13.0.0/scotch-6.1.1-gp3scxaylybflfgo4c52pmjtgs2jggjw/lib -Wl,-rpath,/home/sajid/packages/spack/opt/spack/linux-ubuntu20.04-zen2/clang-13.0.0/zlib-1.2.11-hwlylittu23vvaixdrtuld7qt3a2h4uj/lib -L/home/sajid/packages/spack/opt/spack/linux-ubuntu20.04-zen2/clang-13.0.0/zlib-1.2.11-hwlylittu23vvaixdrtuld7qt3a2h4uj/lib -Wl,-rpath,/home/sajid/packages/spack/opt/spack/linux-ubuntu20.04-zen2/clang-13.0.0/hdf5-1.12.1-vo7rvdpj4kn7gmdkrcdh5pl7w2ouuriy/lib -L/home/sajid/packages/spack/opt/spack/linux-ubuntu20.04-zen2/clang-13.0.0/hdf5-1.12.1-vo7rvdpj4kn7gmdkrcdh5pl7w2ouuriy/lib -Wl,-rpath,/home/sajid/packages/spack/opt/spack/linux-ubuntu20.04-zen2/clang-13.0.0/parmetis-4.0.3-6rjlc7yzlksa5vlldsh65iu2uhm32kol/lib -L/home/sajid/packages/spack/opt/spack/linux-ubuntu20.04-zen2/clang-13.0.0/parmetis-4.0.3-6rjlc7yzlksa5vlldsh65iu2uhm32kol/lib -Wl,-rpath,/home/sajid/packages/spack/opt/spack/linux-ubuntu20.04-zen2/clang-13.0.0/metis-5.1.0-bcj7iptdg36qwsxfvcxuv4gzm4rcdz6d/lib -L/home/sajid/packages/spack/opt/spack/linux-ubuntu20.04-zen2/clang-13.0.0/metis-5.1.0-bcj7iptdg36qwsxfvcxuv4gzm4rcdz6d/lib -Wl,-rpath,/home/sajid/packages/spack/opt/spack/linux-ubuntu20.04-zen2/clang-13.0.0/hwloc-2.7.0-cobsqzticue7y6xswgrcnhczkohbt5le/lib -L/home/sajid/packages/spack/opt/spack/linux-ubuntu20.04-zen2/clang-13.0.0/hwloc-2.7.0-cobsqzticue7y6xswgrcnhczkohbt5le/lib -Wl,-rpath,/home/sajid/packages/spack/opt/spack/linux-ubuntu20.04-zen2/clang-13.0.0/mpich-3.4.2-fizqettdbupbpgrurxak3vq64nz5jqss/lib -L/home/sajid/packages/spack/opt/spack/linux-ubuntu20.04-zen2/clang-13.0.0/mpich-3.4.2-fizqettdbupbpgrurxak3vq64nz5jqss/lib -Wl,-rpath,/home/sajid/packages/spack/opt/spack/linux-ubuntu20.04-zen2/gcc-9.3.0/gcc-11.2.0-36ugcqpr5laqaukcht5ldyi6eh4e4ddu/lib64 -Wl,-rpath,/home/sajid/packages/spack/opt/spack/linux-ubuntu20.04-zen2/gcc-9.3.0/gcc-11.2.0-36ugcqpr5laqaukcht5ldyi6eh4e4ddu/lib/gcc/x86_64-pc-linux-gnu/11.2.0 -L/home/sajid/packages/spack/opt/spack/linux-ubuntu20.04-zen2/gcc-9.3.0/gcc-11.2.0-36ugcqpr5laqaukcht5ldyi6eh4e4ddu/lib/gcc/x86_64-pc-linux-gnu/11.2.0 -L/home/sajid/packages/spack/opt/spack/linux-ubuntu20.04-zen2/gcc-9.3.0/gcc-11.2.0-36ugcqpr5laqaukcht5ldyi6eh4e4ddu/lib64 -Wl,-rpath,/home/sajid/packages/spack/opt/spack/linux-ubuntu20.04-zen2/gcc-9.3.0/gcc-11.2.0-36ugcqpr5laqaukcht5ldyi6eh4e4ddu/lib -L/home/sajid/packages/spack/opt/spack/linux-ubuntu20.04-zen2/gcc-9.3.0/gcc-11.2.0-36ugcqpr5laqaukcht5ldyi6eh4e4ddu/lib -Wl,-rpath,/home/sajid/packages/spack/opt/spack/linux-ubuntu20.04-zen2/gcc-11.2.0/llvm-13.0.0-igzxdbdikhixp3czhzxq3b4zo6rycypk/lib -L/home/sajid/packages/spack/opt/spack/linux-ubuntu20.04-zen2/gcc-11.2.0/llvm-13.0.0-igzxdbdikhixp3czhzxq3b4zo6rycypk/lib -lHYPRE -lstrumpack -lscalapack -lsuperlu_dist -lkokkoskernels -lkokkoscontainers -lkokkoscore -lopenblas -lptesmumps -lptscotch -lptscotcherr -lscotch -lscotcherr -lz -lpthread -lhdf5_hl -lhdf5 -lparmetis -lmetis -lm -lz -ldl -lmpifort -lmpi -lgfortran -lm -lgfortran -lm -lgcc_s -lquadmath -ldl -lmpicxx -lmpi -lc++ -lm -lgcc_s -ldl
-----------------------------------------

